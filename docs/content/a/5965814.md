---
title: "[Q#5965767][A#5965814] Performance of StringTokenizer class vs. String.split method in Java"
question_title: "Performance of StringTokenizer class vs. String.split method in Java"
question_text: "In my software I need to split string into words. I currently have more than 19,000,000 documents with more than 30 words each. Which of the following two ways is the best way to do this (in terms of performance)? or"
answer_text: "If your data already in a database you need to parse the string of words, I would suggest using indexOf repeatedly.  Its many times faster than either solution. However, getting the data from a database is still likely to much more expensive. prints The cost of opening a file will be about 8 ms. As the files are so small, your cache may improve performance by a factor of 2-5x. Even so its going to spend ~10 hours opening files. The cost of using split vs StringTokenizer is far less than 0.01 ms each. To parse 19 million x 30 words * 8 letters per word should take about 10 seconds (at about 1 GB per 2 seconds) If you want to improve performance, I suggest you have far less files. e.g. use a database. If you don't want to use an SQL database, I suggest using one of these http://nosql-database.org/"
apization_code: "package com.stackoverflow.api;  import java.util.ArrayList; import java.util.Arrays; import java.util.List; import java.util.StringTokenizer; import java.util.regex.Pattern;  /**  * Performance of StringTokenizer class vs. String.split method in Java  *  * @author APIzator  * @see <a href=\"https://stackoverflow.com/a/5965814\">https://stackoverflow.com/a/5965814</a>  */ public class APIzator5965814 {    public static void performance(int runs) throws Exception {     StringBuilder sb = new StringBuilder();     for (int i = 100000; i < 100000 + 60; i++) sb.append(i).append(' ');     String sample = sb.toString();     for (int i = 0; i < 5; i++) {       {         long start = System.nanoTime();         for (int r = 0; r < runs; r++) {           StringTokenizer st = new StringTokenizer(sample);           List<String> list = new ArrayList<String>();           while (st.hasMoreTokens()) list.add(st.nextToken());         }         long time = System.nanoTime() - start;         System.out.printf(           \"StringTokenizer took an average of %.1f us%n\",           time / runs / 1000.0         );       }       {         long start = System.nanoTime();         Pattern spacePattern = Pattern.compile(\" \");         for (int r = 0; r < runs; r++) {           List<String> list = Arrays.asList(spacePattern.split(sample, 0));         }         long time = System.nanoTime() - start;         System.out.printf(           \"Pattern.split took an average of %.1f us%n\",           time / runs / 1000.0         );       }       {         long start = System.nanoTime();         for (int r = 0; r < runs; r++) {           List<String> list = new ArrayList<String>();           int pos = 0, end;           while ((end = sample.indexOf(' ', pos)) >= 0) {             list.add(sample.substring(pos, end));             pos = end + 1;           }         }         long time = System.nanoTime() - start;         System.out.printf(           \"indexOf loop took an average of %.1f us%n\",           time / runs / 1000.0         );       }     }   } }"
---

https://stackoverflow.com/q/5965767

In my software I need to split string into words. I currently have more than 19,000,000 documents with more than 30 words each.
Which of the following two ways is the best way to do this (in terms of performance)?
or


<div class="code-logo"><img src="/stackoverflow.png" /></div>

```java
StringTokenizer sTokenize = new StringTokenizer(s," ");
while (sTokenize.hasMoreTokens()) {
String[] splitS = s.split(" ");
for(int i =0; i < splitS.length; i++)
```


## Original code snippet

https://stackoverflow.com/a/5965814

If your data already in a database you need to parse the string of words, I would suggest using indexOf repeatedly.  Its many times faster than either solution.
However, getting the data from a database is still likely to much more expensive.
prints
The cost of opening a file will be about 8 ms. As the files are so small, your cache may improve performance by a factor of 2-5x. Even so its going to spend ~10 hours opening files. The cost of using split vs StringTokenizer is far less than 0.01 ms each. To parse 19 million x 30 words * 8 letters per word should take about 10 seconds (at about 1 GB per 2 seconds)
If you want to improve performance, I suggest you have far less files. e.g. use a database. If you don&#x27;t want to use an SQL database, I suggest using one of these http://nosql-database.org/

<div class="code-logo"><img src="/stackoverflow.png" /></div>

```java
StringBuilder sb = new StringBuilder();
for (int i = 100000; i < 100000 + 60; i++)
    sb.append(i).append(' ');
String sample = sb.toString();

int runs = 100000;
for (int i = 0; i < 5; i++) {
    {
        long start = System.nanoTime();
        for (int r = 0; r < runs; r++) {
            StringTokenizer st = new StringTokenizer(sample);
            List<String> list = new ArrayList<String>();
            while (st.hasMoreTokens())
                list.add(st.nextToken());
        }
        long time = System.nanoTime() - start;
        System.out.printf("StringTokenizer took an average of %.1f us%n", time / runs / 1000.0);
    }
    {
        long start = System.nanoTime();
        Pattern spacePattern = Pattern.compile(" ");
        for (int r = 0; r < runs; r++) {
            List<String> list = Arrays.asList(spacePattern.split(sample, 0));
        }
        long time = System.nanoTime() - start;
        System.out.printf("Pattern.split took an average of %.1f us%n", time / runs / 1000.0);
    }
    {
        long start = System.nanoTime();
        for (int r = 0; r < runs; r++) {
            List<String> list = new ArrayList<String>();
            int pos = 0, end;
            while ((end = sample.indexOf(' ', pos)) >= 0) {
                list.add(sample.substring(pos, end));
                pos = end + 1;
            }
        }
        long time = System.nanoTime() - start;
        System.out.printf("indexOf loop took an average of %.1f us%n", time / runs / 1000.0);
    }
 }
StringTokenizer took an average of 5.8 us
Pattern.split took an average of 4.8 us
indexOf loop took an average of 1.8 us
StringTokenizer took an average of 4.9 us
Pattern.split took an average of 3.7 us
indexOf loop took an average of 1.7 us
StringTokenizer took an average of 5.2 us
Pattern.split took an average of 3.9 us
indexOf loop took an average of 1.8 us
StringTokenizer took an average of 5.1 us
Pattern.split took an average of 4.1 us
indexOf loop took an average of 1.6 us
StringTokenizer took an average of 5.0 us
Pattern.split took an average of 3.8 us
indexOf loop took an average of 1.6 us
```

## Produced APIzation

[`APIzator5965814.java`](https://github.com/pasqualesalza/apization/raw/main/data/search/APIzator5965814.java)

<div class="code-logo"><img src="/apizator.png" /></div>

```java
package com.stackoverflow.api;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.StringTokenizer;
import java.util.regex.Pattern;

/**
 * Performance of StringTokenizer class vs. String.split method in Java
 *
 * @author APIzator
 * @see <a href="https://stackoverflow.com/a/5965814">https://stackoverflow.com/a/5965814</a>
 */
public class APIzator5965814 {

  public static void performance(int runs) throws Exception {
    StringBuilder sb = new StringBuilder();
    for (int i = 100000; i < 100000 + 60; i++) sb.append(i).append(' ');
    String sample = sb.toString();
    for (int i = 0; i < 5; i++) {
      {
        long start = System.nanoTime();
        for (int r = 0; r < runs; r++) {
          StringTokenizer st = new StringTokenizer(sample);
          List<String> list = new ArrayList<String>();
          while (st.hasMoreTokens()) list.add(st.nextToken());
        }
        long time = System.nanoTime() - start;
        System.out.printf(
          "StringTokenizer took an average of %.1f us%n",
          time / runs / 1000.0
        );
      }
      {
        long start = System.nanoTime();
        Pattern spacePattern = Pattern.compile(" ");
        for (int r = 0; r < runs; r++) {
          List<String> list = Arrays.asList(spacePattern.split(sample, 0));
        }
        long time = System.nanoTime() - start;
        System.out.printf(
          "Pattern.split took an average of %.1f us%n",
          time / runs / 1000.0
        );
      }
      {
        long start = System.nanoTime();
        for (int r = 0; r < runs; r++) {
          List<String> list = new ArrayList<String>();
          int pos = 0, end;
          while ((end = sample.indexOf(' ', pos)) >= 0) {
            list.add(sample.substring(pos, end));
            pos = end + 1;
          }
        }
        long time = System.nanoTime() - start;
        System.out.printf(
          "indexOf loop took an average of %.1f us%n",
          time / runs / 1000.0
        );
      }
    }
  }
}

```